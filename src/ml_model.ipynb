{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9b2b43e-6b16-44fd-931d-e963367a7bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using device: cpu\n",
      "Epoch 1/150, Loss: 1.2771, Val Loss: 0.5469\n",
      "Epoch 11/150, Loss: 0.8256, Val Loss: 0.4277\n",
      "Epoch 21/150, Loss: 0.6757, Val Loss: 0.3568\n",
      "Epoch 31/150, Loss: 0.5636, Val Loss: 0.2673\n",
      "Epoch 41/150, Loss: 0.4873, Val Loss: 0.2470\n",
      "Epoch 51/150, Loss: 0.4388, Val Loss: 0.2433\n",
      "Epoch 61/150, Loss: 0.4045, Val Loss: 0.2361\n",
      "Epoch 71/150, Loss: 0.3763, Val Loss: 0.2209\n",
      "Epoch 81/150, Loss: 0.3407, Val Loss: 0.1992\n",
      "Epoch 91/150, Loss: 0.3149, Val Loss: 0.1966\n",
      "Epoch 101/150, Loss: 0.2913, Val Loss: 0.1912\n",
      "Epoch 111/150, Loss: 0.2714, Val Loss: 0.1765\n",
      "Epoch 121/150, Loss: 0.2546, Val Loss: 0.1776\n",
      "Epoch 131/150, Loss: 0.2394, Val Loss: 0.1700\n",
      "Epoch 141/150, Loss: 0.2261, Val Loss: 0.1680\n",
      "Epoch 150/150, Loss: 0.2154, Val Loss: 0.1564\n",
      "✅ Saved model and scalers\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import joblib\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Load & Prepare Data\n",
    "# ----------------------------\n",
    "df = pd.read_csv(\"benchmark_results 1.csv\")\n",
    "\n",
    "# Feature Engineering\n",
    "df[\"nodes_per_partition\"] = df[\"num_nodes\"] / df[\"partition_size\"]\n",
    "df[\"edge_density\"] = df[\"num_edges\"] / (df[\"num_nodes\"]**2)\n",
    "df[\"size_ratio\"] = df[\"matrix_size\"] / df[\"partition_size\"]\n",
    "\n",
    "# Features\n",
    "X = df[[\"num_nodes\", \"num_edges\", \"average_degree\", \"nodes_per_partition\", \"edge_density\", \"size_ratio\"]].values\n",
    "\n",
    "# Target: Normalized runtime\n",
    "runtime_scaler = StandardScaler()\n",
    "feature_scaler = StandardScaler()\n",
    "X_scaled = feature_scaler.fit_transform(X)  # Scale features FIRST\n",
    "y = runtime_scaler.fit_transform(df[[\"runtime\"]]).flatten()\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Train/Val/Test Split\n",
    "# ----------------------------\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_val_t = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_t = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Device Configuration (GPU or CPU)\n",
    "# ----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Using device: {device}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Define Neural Network Model (with Batch Normalization)\n",
    "# ----------------------------\n",
    "class ConfigPredictor(nn.Module):\n",
    "    def __init__(self, input_dim=6):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1)  # Output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = ConfigPredictor().to(device)\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Training Setup (AdamW Optimizer)\n",
    "# ----------------------------\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.001)  # AdamW\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10)\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Training Loop\n",
    "# ----------------------------\n",
    "EPOCHS = 150\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_t.to(device))\n",
    "    loss = loss_fn(outputs, y_train_t.to(device))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_t.to(device))\n",
    "        val_loss = loss_fn(val_outputs, y_val_t.to(device))\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == EPOCHS - 1:\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_config_predictor.pth\")\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Save Model and Scalers\n",
    "# ----------------------------\n",
    "model.load_state_dict(torch.load(\"best_config_predictor.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Save model\n",
    "torch.save(model, \"config_predictor.pth\")\n",
    "\n",
    "joblib.dump(runtime_scaler, \"runtime_scaler.pkl\")\n",
    "joblib.dump(feature_scaler, \"feature_scaler.pkl\")\n",
    "\n",
    "print(\"✅ Saved model and scalers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d9e11e-04eb-4b06-860c-cb190dc381ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
